{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WuEfEVo2seo"
      },
      "source": [
        "# EE675A - Assignment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i29hbFMG2ses"
      },
      "source": [
        "**Name:**  <br />\n",
        "**Roll No:**\n",
        "***\n",
        "## Instructions\n",
        "\n",
        "- **Release Date**: **21st Jan 2024**  \n",
        "- **Deadline**: **Part B : 4th Feb 2024 11:59PM**\n",
        "- Kindly name your submission files as `RollNo_Name_A1_PartB.ipynb`, based on the part you are submitting. Marks will be deducted for all submissions that do not follow the naming guidelines. <br />\n",
        "- You are required to work out your answers and submit only the iPython Notebook. The code should be well commented and easy to understand as there are marks for this. This notebook can be used as a template for assignment submission. <br />\n",
        "- Submissions are to be made through HelloIITK portal. Submissions made through mail will not be graded.<br />\n",
        "- Answers to the theory questions if any should be included in the notebook itself. While using special symbols use the $\\LaTeX$ mode <br />\n",
        "- Make sure your plots are clear and have title, legends and clear lines, etc. <br />\n",
        "- Plagiarism of any form will not be tolerated. If your solutions are found to match with other students or from other uncited sources, there will be heavy penalties and the incident will be reported to the disciplinary authorities. <br />\n",
        "- In case you have any doubts, feel free to reach out to TAs for help. <br />\n",
        "\n",
        "***\n",
        "## Introduction\n",
        "\n",
        "You are free to use parts of the given code but may also choose to write the whole thing on your own.  \n",
        "The illustrations for Part-B are adapted from [Alejandro's blog post](https://medium.com/@alejandro.aristizabal24/understanding-reinforcement-learning-hands-on-part-2-multi-armed-bandits-526592072bdc) on Multi-Armed Bandits. Throughout the course we will be using the [Gymnasium toolkit](https://gymnasium.farama.org/index.html) for the assignements so before starting you may want to go through the [basic usage](https://gymnasium.farama.org/content/basic_usage/) and basics of gymnasium and the installation procedure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wON2nVET2set",
        "tags": []
      },
      "source": [
        "***\n",
        "# Part B: Multi-armed bandits\n",
        "## Demo and Preliminaries\n",
        "\n",
        "We will begin by getting familiar with the basic problem setup before we dig in to the actual assignement problems. Let's start by loading all the required libraries for this notebook. For generating plots you must have `ipympl` installed and `jupyter-matplotlib` extension installed and enabled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H89KRE9N2seu",
        "outputId": "56c6f45e-5b2e-4a12-dbd0-f25047f1e83d"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "!python.exe -m pip install --upgrade pip\n",
        "!pip install \"gymnasium\"\n",
        "!pip install ipympl\n",
        "!pip install matplotlib\n",
        "!pip install tqdm\n",
        "%matplotlib widget\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import gymnasium as gym\n",
        "from tqdm import tqdm\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O01qmZN2sev"
      },
      "source": [
        "## Scenario\n",
        "\n",
        "The Multi-Armed Bandit describes a situation in which an agent has only one state, and multiple actions to interact with the environment. Each action gives a random reward, centered on an unkown value. Our agent wants to maximize the reward received, which means it wants to find the action that yields a higher reward. Based on this, let's build the scenario.\n",
        "\n",
        "We're going to implement the multi-armed bandit environment using OpenAI's gym interface. Also, our implementation will be vectorized for the sake of optimization. This allows us to run multiple agents on multiple environments at the same time. The code below is based on [this implementation](https://github.com/diegoalejogm/openai-k-armed-bandits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Vz6nX5I_2sev"
      },
      "outputs": [],
      "source": [
        "from gymnasium import spaces\n",
        "from gymnasium.utils import seeding\n",
        "import gymnasium as gym\n",
        "\n",
        "class ArmedBanditsEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    The famous k-Armed Bandit Environment, implemented for the gym interface.\n",
        "    Initialization requires an array of length equals to k, where each item is\n",
        "    a function which samples from a specified distribution.\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, mean, stddev):\n",
        "        assert len(mean.shape) == 2\n",
        "        assert len(stddev.shape) == 2\n",
        "\n",
        "        super(ArmedBanditsEnv, self).__init__()\n",
        "        # Define action and observation space\n",
        "        self.num_bandits = mean.shape[1]\n",
        "        self.num_experiments = mean.shape[0]\n",
        "        self.action_space = spaces.Discrete(self.num_bandits)\n",
        "\n",
        "        # Theres one state only in the k-armed bandits problem\n",
        "        self.observation_space = spaces.Discrete(1)\n",
        "        self.mean = mean\n",
        "        self.stddev = stddev\n",
        "\n",
        "    def step(self, action):\n",
        "        # Sample from the specified bandit using it's reward distribution\n",
        "        assert (action < self.num_bandits).all()\n",
        "\n",
        "        sampled_means = self.mean[np.arange(self.num_experiments),action]\n",
        "        sampled_stddevs = self.stddev[np.arange(self.num_experiments),action]\n",
        "\n",
        "        reward = np.random.normal(loc=sampled_means, scale=sampled_stddevs, size=(1,self.num_experiments))\n",
        "\n",
        "        # Return a constant state of 0. Our environment has no terminal state\n",
        "        observation, done, info = 0, False, dict()\n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def reset(self):\n",
        "        return 0\n",
        "\n",
        "    def render(self, mode='human', close=False):\n",
        "        pass\n",
        "         \n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np.random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def close(self):\n",
        "        pass\n",
        "\n",
        "\n",
        "class ArmedBanditsGaussian(ArmedBanditsEnv):\n",
        "    def __init__(self, num_experiments=1, num_bandits=3):\n",
        "        self.means = np.random.normal(size=(num_experiments, num_bandits))\n",
        "\n",
        "        ArmedBanditsEnv.__init__(self, self.means, np.ones((num_experiments, num_bandits)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWmKZ0uX2sew"
      },
      "source": [
        "Here we're creating two classes, `ArmedBanditsEnv` is the main class, while `ArmedBanditsGaussian` is an auxiliary class that allows us to easily create an environment with random mean rewards for each action. Our environment receives numpy arrays for the means and standard deviations for each action. The dimensions of this arrays are described as `num_experiments`x`num_bandits`. Taking a step requires a numpy vector of size `num_experiments`, where each value specifies which action to take for each experiment. The step functions returns, among other information, a vector of reward obtained for each experiment. Let's see this in action:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rc9rBv-T2sex",
        "outputId": "73f66c80-6c1b-4fc5-e7a8-b7f780f934c6"
      },
      "outputs": [],
      "source": [
        "means = np.array([[5, 1, 0, -10]]) # The mean for a four-armed bandit. Single experiment\n",
        "stdev = np.array([[1, 0.1, 5, 1]]) # The standard deviation for a four-armed bandit.\n",
        "\n",
        "env = ArmedBanditsEnv(means, stdev) # Create the environment\n",
        "\n",
        "for i in range(4):\n",
        "    action = np.array([[i]])\n",
        "    _, reward, _, _ = env.step(action)\n",
        "    print(\"Bandit:\", i, \" gave a reward of:\", reward[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSsziz9u2sey"
      },
      "source": [
        "## Evaluating our actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8g7dhvZ2sez"
      },
      "source": [
        "In order to learn something from our interaction with the environment, we need to know how exactly we determine the value of our actions, as well as how to keep that value up to date. A simple strategy our agents can take is to calculate the expected return for each action. This can be done through experience by taking the average of previous rewards given by a determined action.\n",
        "\n",
        "For example, we can use the next list of rewards to calculate the expected return of the chosen action:\n",
        "\n",
        "$\\bar{\\mu}_n = \\dfrac{R_1+R_2+\\dots+R_n}{n}$\n",
        "\n",
        "Having to store all the previously seen rewards to calculate the value of an action is cumbersome, inefficient and unnecessary. We can derive another form of average, called *Incremental average update rule*, which only requires us to know the previous average $\\bar{\\mu}_{n-1}$ and the number $n$:\n",
        "\n",
        "$\\bar{\\mu}_n = \\bar{\\mu}_{n-1} + \\dfrac{1}{n}(R_n - \\bar{\\mu}_{n-1})$\n",
        "\n",
        "Here's a small demonstration of this function at work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hvBWbzZ2sez",
        "outputId": "645bd8fe-9160-4774-fdca-f02680baeb79"
      },
      "outputs": [],
      "source": [
        "def inc_avg(prev_avg, new_val, n):\n",
        "    return prev_avg + 1/n*(new_val - prev_avg)\n",
        "\n",
        "# Obtain the previous average\n",
        "vals = np.array([4.5, 5.04, 5.32, 4.8, 5.11])\n",
        "prev_avg = vals.mean()\n",
        "\n",
        "# Calculate a new average using the incremental average update function\n",
        "new_val = 5.18\n",
        "new_avg = inc_avg(prev_avg, new_val, 6)\n",
        "\n",
        "# Calculate the same average using all previous values for comparison\n",
        "avg = np.append(vals, new_val).mean()\n",
        "\n",
        "print(\"Average obtained from incremental update rule: \", new_avg)\n",
        "print(\"Average obtained from basic average function:  \", avg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di0QdX_n2sez"
      },
      "source": [
        "This method will be used on the next strategies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEuDOZ852se0"
      },
      "source": [
        "## The Greedy Agent\n",
        "\n",
        "This strategy is focused on always choosing the best known action at the time. Every time the agent takes an action, it looks at the estimated values for each action, and chooses the one that has a greater score. If more than two values look best, then the agent selects arbitrarily among those best-valued actions. This is called breaking ties arbitrarily\n",
        "\n",
        "Taking the action with the greatest value is equivalent to using the **argmax** function. Although, we need to implement some changes so that the funciton breaks the ties the way we intend it to do:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "IFNJoUd92se0"
      },
      "outputs": [],
      "source": [
        "def argmax(q_values):\n",
        "    \"\"\"\n",
        "    Takes in a matrix of n*k q_values and returns the index\n",
        "    of the item with the highest value for each row.\n",
        "    Breaks ties randomly.\n",
        "    returns: vector of size n, where each item is the index of\n",
        "    the highest value in q_values for each row.\n",
        "    \"\"\"\n",
        "    # Generate a mask of the max values for each row\n",
        "    mask = q_values == q_values.max(axis=1)[:, None]\n",
        "    # Generate noise to be added to the ties\n",
        "    r_noise = 1e-6*np.random.random(q_values.shape)\n",
        "    # Get the argmax of the noisy masked values\n",
        "    return np.argmax(r_noise*mask,axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfXWUrgO2se0"
      },
      "source": [
        "Here we're generating a mask of all the values in the input that are equal to the maximum value. Then ,we generate some noise and multiply it with the mask. Taking the argmax of this new list will be equivalent to the desired argmax with ties broken arbitrarily.\n",
        "\n",
        "Now that we have specified the argmax function, we can declare our class for the Greedy Agent, which is capable of acting upon the environment, and updating its estimates after receiving a reward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "dUjX3Vz02se1"
      },
      "outputs": [],
      "source": [
        "class GreedyAgent:\n",
        "    def __init__(self, reward_estimates):\n",
        "        \"\"\"\n",
        "        Our agent takes as input the initial reward estimates.\n",
        "        This estimates will be updated incrementally after each\n",
        "        interaction with the environment.\n",
        "        \"\"\"\n",
        "        assert len(reward_estimates.shape) == 2\n",
        "\n",
        "        self.num_bandits = reward_estimates.shape[1]\n",
        "        self.num_experiments = reward_estimates.shape[0]\n",
        "        self.reward_estimates = reward_estimates.astype(np.float64)\n",
        "        self.action_count = np.zeros(reward_estimates.shape)\n",
        "\n",
        "    def get_action(self):\n",
        "        # Our agent is greedy, so there's no need for exploration.\n",
        "        # Our argmax will do just fine for this situation\n",
        "        action = argmax(self.reward_estimates)\n",
        "\n",
        "        # Add a 1 to each action selected in the action count\n",
        "        self.action_count[np.arange(self.num_experiments), action] += 1\n",
        "\n",
        "        return action\n",
        "\n",
        "    def update_estimates(self, reward, action):\n",
        "        # rew is a matrix with the obtained rewards from our previuos\n",
        "        # action. Use this to update our estimates incrementally\n",
        "        n = self.action_count[np.arange(self.num_experiments), action]\n",
        "        prev_reward_estimates = self.reward_estimates[np.arange(self.num_experiments), action]\n",
        "\n",
        "        # Update the reward estimates incementally\n",
        "        self.reward_estimates[np.arange(self.num_experiments), action] = inc_avg(prev_reward_estimates,reward,n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkLDTxGg2se1"
      },
      "source": [
        "The greedy agent contains a matrix for the estimates, as well as for the number of times each action has been taken. This is necessary for using the incremental average update rule, used inside the `update_estimates` function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQmJ4qtp2se1"
      },
      "source": [
        "### Testing the agent\n",
        "\n",
        "Let's see how the Greedy Agent behaves on the environment. For this, we're going to generate some animations where we're able to see how the agent estimates the values for each action, as well as the real values provided by the environment. Remember that the agent doesn't have access to that information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "Z_jM_1_W2se1",
        "outputId": "f7b7250a-d084-4e87-a924-dc87518c5ec1"
      },
      "outputs": [],
      "source": [
        "# Initialize the environment of our multi-armed bandit problem\n",
        "num_experiments = 2\n",
        "num_bandits = 8\n",
        "num_steps = 100\n",
        "means = np.random.normal(size=(num_experiments, num_bandits))\n",
        "stdev = np.ones((num_experiments, num_bandits))\n",
        "\n",
        "env = ArmedBanditsEnv(means, stdev)\n",
        "\n",
        "# Initialize the agent\n",
        "agent = GreedyAgent(np.zeros((num_experiments,num_bandits)))\n",
        "\n",
        "# Code for plotting the interaction\n",
        "fig, axs = plt.subplots(1, num_experiments, figsize=(10, 4))\n",
        "x_pos = np.arange(num_bandits)\n",
        "\n",
        "def init():\n",
        "    axa = [];\n",
        "    for i in range(num_experiments):\n",
        "        init_ax(i)\n",
        "        # axa.append(init_ax(i))\n",
        "    # return axa\n",
        "\n",
        "def init_ax(i):\n",
        "    ax = axs[i]\n",
        "    ax.clear()\n",
        "    ax.set_ylim(-4, 4)\n",
        "    ax.set_xlim(-0.5, num_bandits-.5)\n",
        "    ax.set_xlabel('Actions', fontsize=14)\n",
        "    ax.set_ylabel('Value', fontsize=14)\n",
        "    ax.set_title(label='Estimated Values vs. Real values', fontsize=15)\n",
        "    ax.plot(x_pos, env.mean[i], marker='D', linestyle='', alpha=0.8, color='r', label='Real Values')\n",
        "    ax.axhline(0, color='black', lw=1)\n",
        "    # return ax\n",
        "\n",
        "\n",
        "# Implement a step, which involves the agent acting upon the\n",
        "# environment and learning from the received reward.\n",
        "def step(g):\n",
        "    action = agent.get_action()\n",
        "    _, reward, _, _ = env.step(action)\n",
        "    agent.update_estimates(reward, action)\n",
        "    axa = []\n",
        "    for i in range(num_experiments):\n",
        "        ax = axs[i]\n",
        "        # Plot the estimated values from the agent compared to the real values\n",
        "        estimates = agent.reward_estimates[i]\n",
        "        init_ax(i)\n",
        "        values = ax.bar(x_pos, estimates, align='center', color='blue', alpha=0.4, label='Estimated Values')\n",
        "        ax.legend()\n",
        "        # axa.append(ax)\n",
        "    # return axa\n",
        "\n",
        "anim = FuncAnimation(fig, func=step, frames=num_steps, init_func=init, interval=10, repeat=False, blit=True)\n",
        "plt.show()\n",
        "\n",
        "# Uncomment the next line if you wish to store the animations as a gif\n",
        "# anim.save('./greedy-agent.gif', writer='imagemagick', fps=60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liI8-lBU2se2"
      },
      "source": [
        "you may try the previous block of code multiple times to see multiple animations. In general, you may realize that most of the actions are not explored by the agent, and that it will mostly stick to the one action that gave it some positive reward. The agent is good at evading negative values, but it will only land on the optimal action by pure chance.\n",
        "\n",
        "We can plot the average behavior by doing more experiments. The next plot displays the percentage of times the agent chose the optimal action over an average of 10000 experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "mBAlPJxg2se2",
        "outputId": "49f8e83b-2c7f-4681-8fdb-8c353c7585d6"
      },
      "outputs": [],
      "source": [
        "num_experiments = 10000\n",
        "num_steps = 1000\n",
        "num_actions = 10\n",
        "\n",
        "# Initialize the environment\n",
        "env = ArmedBanditsGaussian(num_experiments, num_actions)\n",
        "# Initialize the agent\n",
        "agent = GreedyAgent(np.zeros((num_experiments, num_actions)))\n",
        "\n",
        "# Store the scores and averages for later plotting\n",
        "averages = np.zeros((num_steps))\n",
        "optimality = np.zeros((num_steps))\n",
        "scores = np.zeros((num_experiments, num_steps+1))\n",
        "\n",
        "#Store the optimal actions for later use\n",
        "optimal = np.argmax(env.mean, axis=1)\n",
        "\n",
        "for i in tqdm(range(num_steps)):\n",
        "    # Select an action to execute on the environment\n",
        "    action = agent.get_action()\n",
        "    _, reward, _, _ = env.step(action)\n",
        "\n",
        "    # Update the agent estimates with the previously observed rewards\n",
        "    agent.update_estimates(reward, action)\n",
        "\n",
        "    # Store the average cumulative score and optimality of the current step\n",
        "    scores[:,i+1] = scores[:,i] + reward\n",
        "    avg_score = np.mean(scores[:,i+1]/(i+1))\n",
        "    averages[i] = avg_score\n",
        "\n",
        "    # Get optimal actions from the environment\n",
        "    current_optimality = np.mean(action == optimal)\n",
        "    optimality[i] = current_optimality\n",
        "\n",
        "plt.figure(figsize=(12,6), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.plot([1.0 for _ in range(num_steps)], linestyle='--')\n",
        "plt.plot([0.0 for _ in range(num_steps)], linestyle='--')\n",
        "plt.plot(optimality)\n",
        "plt.legend([\"Best Possible\", \"Worst Possible\", \"Greedy\"])\n",
        "plt.title(\"Average Optimality of Greedy Agent\", fontsize=14)\n",
        "plt.ylabel(\"% of Optimal Action Taken\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.show()\n",
        "greedy_scores = averages\n",
        "greedy_optimality = optimality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWa-6MVh2se3"
      },
      "source": [
        "The Greedy Agent chooses the best action on average ~40% of the times. Additionally, extra experience won't improve it's score, as it usually lands on a sub-optimal action on the first steps, and stays there for ever. The Greedy Agent is not a good strategy for finding the optimal action on this scenario."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKr4rdEa2se3"
      },
      "source": [
        "## The Epsilon-Greedy Agent\n",
        "\n",
        "Another strategy is the Epsilon Greedy Agent, which adds to the previous strategy. An Epsilon-Greedy Agent allows for some exploratory actions, by every once in a while choosing any action randomly, instead of always acting greedily. The probability of taking an exploratory action is defined by the parameter `epsilon`. An epsilon of `0` is a Greedy Agent. An epsilon of `0.2` means our agent takes a random action 20% of the time. An epsilon of `1` is an agent that behaves randomly. Let's build this new agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Poi42r3d2se3"
      },
      "outputs": [],
      "source": [
        "class EpsilonGreedyAgent(GreedyAgent):\n",
        "    def __init__(self, reward_estimates, epsilon):\n",
        "        GreedyAgent.__init__(self, reward_estimates)\n",
        "        # Store the epsilon value\n",
        "        assert epsilon >= 0 and epsilon <= 1\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def get_action(self):\n",
        "        # We need to redefine this function so that it takes an exploratory action with epsilon probability\n",
        "\n",
        "        # One hot encoding: 0 if exploratory, 1 otherwise\n",
        "        action_type = (np.random.random_sample(self.num_experiments) > self.epsilon).astype(int)\n",
        "        # Generate both types of actions for every experiment\n",
        "        exploratory_action = np.random.randint(self.num_bandits, size=self.num_experiments)\n",
        "        greedy_action = argmax(self.reward_estimates)\n",
        "        # Use the one hot encoding to mask the actions for each experiment\n",
        "        action = greedy_action * action_type + exploratory_action * (1 - action_type)\n",
        "\n",
        "        self.action_count[np.arange(self.num_experiments), action] += 1\n",
        "\n",
        "        return action"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1KQFxgD2se3"
      },
      "source": [
        "As may be seen, we're inheriting the `GreedyAgent` implementation, and only changing the `get_action` function. For taking an action, we're using a masking that defines which experiments will choose an action randomly and which will act greedily. Then, we apply that masking between random and greedy actions to obtain the action vector for all of our experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_hRV_Xk2se6"
      },
      "source": [
        "### Testing the Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPE2O8AU2se6"
      },
      "source": [
        "Here, we're going to use the same animation as before to observe how this new strategy behaves. Our agents will have a value of epsilon of `0.1`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "80e4bb527a0c4774a097a1534b213383",
            "f7bf92826b1e4d0ea70266bd394268c4"
          ]
        },
        "id": "SWWsxxsa2se7",
        "outputId": "a2bf3f66-e4dd-482d-a95e-083ed5647110"
      },
      "outputs": [],
      "source": [
        "# Initialize the environment of our multi-armed bandit problem\n",
        "num_experiments = 2\n",
        "num_bandits = 8\n",
        "num_steps = 200\n",
        "means = np.random.normal(size=(num_experiments, num_bandits))\n",
        "stdev = np.ones((num_experiments, num_bandits))\n",
        "\n",
        "env = ArmedBanditsEnv(means, stdev)\n",
        "\n",
        "# Initialize the agent\n",
        "agent = EpsilonGreedyAgent(np.zeros((num_experiments,num_bandits)), 0.1)\n",
        "\n",
        "# Code for plotting the interaction\n",
        "fig, axs = plt.subplots(1, num_experiments, figsize=(10, 4))\n",
        "x_pos = np.arange(num_bandits)\n",
        "\n",
        "def init():\n",
        "    for i in range(num_experiments):\n",
        "        init_ax(i)\n",
        "\n",
        "\n",
        "def init_ax(i):\n",
        "    ax = axs[i]\n",
        "    ax.clear()\n",
        "    ax.set_ylim(-4, 4)\n",
        "    ax.set_xlim(-0.5, num_bandits-.5)\n",
        "    ax.set_xlabel('Actions', fontsize=14)\n",
        "    ax.set_ylabel('Value', fontsize=14)\n",
        "    ax.set_title(label='Estimated Values vs. Real values', fontsize=15)\n",
        "    ax.plot(x_pos, env.mean[i], marker='D', linestyle='', alpha=0.8, color='r', label='Real Values')\n",
        "    ax.axhline(0, color='black', lw=1)\n",
        "\n",
        "# Implement a step, which involves the agent acting upon the\n",
        "# environment and learning from the received reward.\n",
        "def step(g):\n",
        "    action = agent.get_action()\n",
        "    _, reward, _, _ = env.step(action)\n",
        "    agent.update_estimates(reward, action)\n",
        "    for i in range(num_experiments):\n",
        "        ax = axs[i]\n",
        "        # Plot the estimated values from the agent compared to the real values\n",
        "        estimates = agent.reward_estimates[i]\n",
        "        init_ax(i)\n",
        "        values = ax.bar(x_pos, estimates, align='center', color='blue', alpha=0.4, label='Estimated Values')\n",
        "        ax.legend()\n",
        "\n",
        "anim = FuncAnimation(fig, func=step, frames=np.arange(num_steps), init_func=init, interval=10, repeat=False, blit=True)\n",
        "plt.show()\n",
        "\n",
        "# Uncomment the next line if you wish to store the animations as a gif\n",
        "# anim.save('./epsilon-greedy-agent.gif', writer='imagemagick', fps=60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQBszQNX2se7"
      },
      "source": [
        "Again, you may run the previous block multiple times to see different runs. As can be observed, the epsilon-greedy agent not only finds the optimal solution most of the times, but it is also capable of finding close estimated values for all the actions! How does our new strategy compares to the greedy agent on average?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "gUk7GyL22se7"
      },
      "outputs": [],
      "source": [
        "def run_experiment(num_experiments=1000, num_steps=1000, num_actions=10,epsilon=0.1):\n",
        "    # Initialize the environment\n",
        "    env = ArmedBanditsGaussian(num_experiments, num_actions)\n",
        "    # Initialize the agent\n",
        "    agent = EpsilonGreedyAgent(np.zeros((num_experiments, num_actions)), epsilon)\n",
        "\n",
        "    # Store the scores and averages for later plotting\n",
        "    averages = np.zeros((num_steps))\n",
        "    optimality = np.zeros((num_steps))\n",
        "    scores = np.zeros((num_experiments, num_steps+1))\n",
        "\n",
        "    #Store the optimal actions for later use\n",
        "    optimal = np.argmax(env.mean, axis=1)\n",
        "\n",
        "    for i in tqdm(range(num_steps)):\n",
        "        # Select an action to execute on the environment\n",
        "        action = agent.get_action()\n",
        "        _, reward, _, _ = env.step(action)\n",
        "\n",
        "        # Update the agent estimates with the previously observed rewards\n",
        "        agent.update_estimates(reward, action)\n",
        "\n",
        "        # Store the average cumulative score and optimality of the current step\n",
        "        scores[:,i+1] = scores[:,i] + reward\n",
        "        avg_score = np.mean(scores[:,i+1]/(i+1))\n",
        "        averages[i] = avg_score\n",
        "\n",
        "        # Get optimal actions from the environment\n",
        "        current_optimality = np.mean(action == optimal)\n",
        "        optimality[i] = current_optimality\n",
        "    return optimality, averages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "ee23248ec89842c38e0a0ceb72fc232b",
            "b929f3fc9e414c4db31e2c9a00e617b1"
          ]
        },
        "id": "RLNOrcM82se7",
        "outputId": "edab55e8-00ab-4a91-ad48-da7a5c159836"
      },
      "outputs": [],
      "source": [
        "num_experiments = 10000\n",
        "num_steps = 1000\n",
        "num_actions = 10\n",
        "epsilon = 0.1\n",
        "\n",
        "balanced_eps_optimality, balanced_eps_scores = run_experiment(num_experiments, num_steps, num_actions, epsilon)\n",
        "\n",
        "plt.figure(figsize=(12,6), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.plot([1.0 for _ in range(num_steps)], linestyle='--')\n",
        "plt.plot([0.0 for _ in range(num_steps)], linestyle='--')\n",
        "plt.plot(balanced_eps_optimality)\n",
        "plt.plot(greedy_optimality)\n",
        "plt.legend([\"Best Possible\", \"Worst Possible\", \"0.1 $\\epsilon$ Greedy\", \"Greedy\"])\n",
        "plt.title(\"Average Optimality of Greedy Agent vs Epsilon-Greedy Agent\")\n",
        "plt.ylabel(\"% of Optimal Action Taken\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6yXM3Rw2se8"
      },
      "source": [
        "After 1000 steps, the Epsilon-Greedy Agent is capable of reaching an 80% average optimality. This means that on average, they choose the best possible action 80% of the times after that amount of iterations. We can also see how our agent is capable of improving from experience, contrary to the Greedy Agent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOGGfJRm2se8"
      },
      "source": [
        "## Values for epsilon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zx_9bwy2se8"
      },
      "source": [
        "On the previous example, we used a value for `epsilon` of `0.1`. This means that the agent chose an exploratory action 10% of the times. What would have happened if we chose another action? Like with almost all hyper-parameters in Machine Learning, there's a range of values which behave better than others. Let's make an actual experiment using different values for `epsilon`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "c99d5001fc2a433e8f37c90ddc673b5d",
            "c7cf0cf405e24d7880b8277334aff30b"
          ]
        },
        "id": "G-OedWQ72se8",
        "outputId": "65281e44-d1c6-47f3-cf38-1d6af30e862a"
      },
      "outputs": [],
      "source": [
        "num_experiments = 1000\n",
        "num_steps = 1000\n",
        "num_actions = 10\n",
        "epsilons = np.array([0.0, 0.01, 0.1, 0.4])\n",
        "\n",
        "plt.figure(figsize=(12,6), dpi=80, facecolor='w', edgecolor='k')\n",
        "# plt.plot([1.6 for _ in range(num_steps)], linestyle='--') # why 1.6?\n",
        "\n",
        "\n",
        "for epsilon in epsilons:\n",
        "    _, reward = run_experiment(num_experiments, num_steps, num_actions, epsilon)\n",
        "\n",
        "    plt.plot(reward)\n",
        "\n",
        "# plt.legend([\"Best Possible\"] + epsilons.tolist())\n",
        "plt.legend(epsilons.tolist())\n",
        "plt.title(\"Average reward for multiple values of epsilon\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Average Reward\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2NwECSH2se8"
      },
      "source": [
        "Here, we're plotting the average amount of reward received by the agent. This is because plotting the optimality on this many tests gets too crowded and noisy. As can be seen, the agent with an epsilon of `0.1` was the one that received the most amount of reward. Values of epsilon that are too small take very few exploratory actions, and therefore take a long time to explore and find the most optimal value. On the other hand, values of `epsilon` too high will obstruct the capacity of the agent of acting optimally. Too much exploration gets in the way of exploitation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32BlCjd3HvId"
      },
      "source": [
        "***\n",
        "## Part B questions\n",
        "\n",
        "Now that we have familiarized ourselves with the basic setup let us test a few more stratergies as part of the assignment problem.\n",
        "\n",
        "Consider a two-armed Bernoulli bandit scenario with true means given by $\\mu_1 = \\frac{1}{2}, \\mu_2= \\frac{1}{2}+\\Delta$, for some $\\Delta < \\frac{1}{2}$. Let the time horizon be $T=10000$. `[20 Marks]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B1\n",
        "Take $\\Delta=\\frac{1}{4}$ and run the Monte Carlo simulations to estimate the expected regret of the ETC algorithm which explores each arm $m = T^{2/3} (\\log T)^{1/3}$ times before committing. Specifically, you run the ETC algorithm to compute the sample regret \n",
        "$$ \\mu_2 * T - \\sum_{t=1}^T R_t, $$ \n",
        "where $R_t$ is the reward obtained in time step $t$.\n",
        "\n",
        "Repeat this experiment 500 times and estimate the expected regret by taking the average of the sample regrets you obtained in all those 500 experiments. `[5 Marks]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expected Regret: 242.828\n"
          ]
        }
      ],
      "source": [
        "# write your code for the above part here\n",
        "import numpy as np\n",
        "\n",
        "# Parameters\n",
        "T = 10000\n",
        "num_experiments = 500\n",
        "delta = 1/4\n",
        "\n",
        "# Function to run ETC algorithm for a single experiment\n",
        "def run_ETC_experiment(T, delta):\n",
        "    m = int(T**(2/3)* (np.log(T))**(1/3))\n",
        "    \n",
        "    # True means of arms\n",
        "    mu1 = 1/2\n",
        "    mu2 = 1/2 + delta\n",
        "    \n",
        "    total_regret = 0\n",
        "    reward=0\n",
        "\n",
        "# Exploration of the arms\n",
        "    # Taking m samples from bernoulli distribution with true mean = mu1\n",
        "    sample1=np.random.binomial(m,mu1)\n",
        "    mean1=np.mean(sample1)\n",
        "       \n",
        "    reward+=np.sum(sample1)   # Total reward from first arm while exploration\n",
        "     \n",
        "     # Taking m samples from bernoulli distribution with true mean = mu2\n",
        "    sample2=np.random.binomial(m,mu2)\n",
        "    mean2=np.mean(sample2)\n",
        "    \n",
        "    reward+=np.sum(sample2)  # Total reward from first arm while exploration\n",
        "\n",
        "\n",
        "# Exploiting the arm with the higher observed mean    \n",
        "    if mean1<mean2:\n",
        "        sample3=np.random.binomial(T-2*m,mu2) # Taking the remaining samples from arm 2\n",
        "        reward+=np.sum(sample3)\n",
        "    else:\n",
        "        sample4=np.random.binomial(T-2*m,mu1) # Taking the remaining samples from arm 1\n",
        "        reward+=np.sum(sample4)\n",
        "\n",
        "    regret= mu2*T - reward # Final regret\n",
        "\n",
        "    return regret\n",
        "\n",
        "\n",
        "        \n",
        "        \n",
        "  \n",
        "# Run Monte Carlo simulations\n",
        "regrets = [run_ETC_experiment(T, delta) for _ in range(num_experiments)]\n",
        "\n",
        "# Compute average regret\n",
        "average_regret = np.mean(regrets)\n",
        "\n",
        "print(\"Expected Regret:\", average_regret)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B2\n",
        "\n",
        "Repeat the above for various values of $\\Delta \\in \\{0.05, 0.1, 0.2, 0.3, 0.4, 0.45\\}$ and plot the estimated regret as a function of $\\Delta$ and verify whether it satisfies the regret upper bound we derived in class. `[5 Marks]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# write your code for the above part here\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters\n",
        "T = 10000\n",
        "num_experiments = 500\n",
        "delta_values = [0.05, 0.1, 0.2, 0.3, 0.4, 0.45]\n",
        "\n",
        "# Function to run ETC algorithm for a single experiment\n",
        "def run_ETC_experiment(T, delta):\n",
        "\n",
        "    m = int(T**(2/3)* (np.log(T))**(1/3))\n",
        "    \n",
        "    # True means of arms\n",
        "    mu1 = 1/2\n",
        "    mu2 = 1/2 + delta\n",
        "    \n",
        "    total_regret = 0\n",
        "    reward=0\n",
        "\n",
        "# Exploration of the arms\n",
        "    # Taking m samples from bernoulli distribution with true mean = mu1\n",
        "    sample1=np.random.binomial(m,mu1)\n",
        "    mean1=np.mean(sample1)\n",
        "       \n",
        "    reward+=np.sum(sample1)   # Total reward from first arm while exploration\n",
        "     \n",
        "     # Taking m samples from bernoulli distribution with true mean = mu2\n",
        "    sample2=np.random.binomial(m,mu2)\n",
        "    mean2=np.mean(sample2)\n",
        "    \n",
        "    reward+=np.sum(sample2)  # Total reward from first arm while exploration\n",
        "\n",
        "\n",
        "# Exploiting the arm with the higher observed mean    \n",
        "    if mean1<mean2:\n",
        "        sample3=np.random.binomial(T-2*m,mu2) # Taking the remaining samples from arm 2\n",
        "        reward+=np.sum(sample3)\n",
        "    else:\n",
        "        sample4=np.random.binomial(T-2*m,mu1) # Taking the remaining samples from arm 1\n",
        "        reward+=np.sum(sample4)\n",
        "\n",
        "    regret= mu2*T - reward # Final regret\n",
        "\n",
        "    return regret\n",
        "\n",
        "    \n",
        "# Run simulations for different values of \n",
        "regret_results = []\n",
        "\n",
        "for delta in delta_values:\n",
        "    regrets = [run_ETC_experiment(T, delta) for _ in range(num_experiments)]\n",
        "    average_regret = np.mean(regrets)\n",
        "    regret_results.append(average_regret)\n",
        "\n",
        "# Plotting the graph\n",
        "plt.plot(delta_values, regret_results, marker='o')\n",
        "plt.xlabel(' (Delta)')\n",
        "plt.ylabel('Estimated Regret')\n",
        "plt.title('Estimated Regret vs. ')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B3 \n",
        "Repeat the experiment with the UCB algorithm and plot the comparison with ETC. `[10 Marks]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# write your code for the above part here\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters\n",
        "T = 10000\n",
        "num_experiments = 500\n",
        "delta_values = [0.05, 0.1, 0.2, 0.3, 0.4, 0.45]\n",
        "\n",
        "# Function to run UCB algorithm for a single experiment\n",
        "def ucb_algorithm(num_steps, delta):\n",
        "    true_means = [0.5, 0.5 + delta]\n",
        "    true_means = np.array(true_means)\n",
        "    \n",
        "    total_rewards = np.zeros(2)\n",
        "    arm_pulls = np.zeros(2)\n",
        "\n",
        "    regrets = []\n",
        "\n",
        "    for t in range(1, num_steps+1):\n",
        "        ucb_values = (total_rewards / (arm_pulls + 1e-6)) + np.sqrt((3 * np.log10(T)) / (2 * (arm_pulls + 1e-6))) # Calculating UCB index for each arm which contain the term of both exploration and exploitation\n",
        "        chosen_arm = np.argmax(ucb_values)  # chosing the arm with maxiimum ucb values\n",
        "\n",
        "        # Simulate pulling the chosen arm and observing the reward (Bernoulli distribution)\n",
        "        reward = np.random.binomial(1, true_means[chosen_arm])\n",
        "\n",
        "        # Update statistics\n",
        "        arm_pulls[chosen_arm] += 1\n",
        "        total_rewards[chosen_arm] += reward\n",
        "\n",
        "    net_reward = np.sum(total_rewards)\n",
        "    regret = num_steps * (0.5 + delta) - net_reward   # net regret of UCB algorithm\n",
        "    return regret\n",
        "\n",
        "\n",
        "regret_results_ETC=[]\n",
        "regret_results_UCB = []\n",
        " \n",
        "# Calculating regrets for different given values of delta\n",
        "\n",
        "for delta in delta_values:\n",
        "    regrets_ETC = [run_ETC_experiment(T, delta) for _ in range(num_experiments)]\n",
        "    average_regret_ETC = np.mean(regrets_ETC)\n",
        "    regret_results_ETC.append(average_regret_ETC)\n",
        "\n",
        "\n",
        "    regret_ucb = [ucb_algorithm(T, delta) for _ in range(num_experiments)]\n",
        "    average_regret_ucb = np.mean(regret_ucb)\n",
        "    regret_results_UCB.append(average_regret_ucb)\n",
        "\n",
        "\n",
        "# Plotting the graph\n",
        "plt.plot(delta_values, regret_results_ETC, marker='o', label='ETC')\n",
        "plt.plot(delta_values, regret_results_UCB, marker='x', label='UCB')\n",
        "plt.xlabel(' (Delta)')\n",
        "plt.ylabel('Estimated Regret')\n",
        "plt.title('Estimated Regret Comparison: ETC vs. UCB')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B4\n",
        "(**Bonus**) In the ETC algorithm, assume that we know $\\Delta$, and choose a better $m$ as function of $\\Delta$ and repeat the experiments and compare with UCB. What did you observe?\n",
        "\n",
        "Hint: Check how many samples of exploration are required to make $\\epsilon < \\frac{\\Delta}{2}$ with a high probability of $1-\\frac{1}{T}$. `[5 Marks]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I observed that for m inversly proportional to square of , ETC algorithm is giving better result specially of large ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Function to run ETC algorithm for a single experiment\n",
        "def run_ETC_experiment(T, delta):\n",
        "    # def run_ETC_experiment(T, delta):\n",
        "    m = int((np.log(T))/delta**2)\n",
        "    m=min(m,T/2)\n",
        "    \n",
        "    # True means of arms\n",
        "    mu1 = 1/2\n",
        "    mu2 = 1/2 + delta\n",
        "    \n",
        "    total_regret = 0\n",
        "    reward=0\n",
        "\n",
        "# Exploration of the arms\n",
        "    # Taking m samples from bernoulli distribution with true mean = mu1\n",
        "    sample1=np.random.binomial(m,mu1)\n",
        "    mean1=np.mean(sample1)\n",
        "       \n",
        "    reward+=np.sum(sample1)   # Total reward from first arm while exploration\n",
        "     \n",
        "     # Taking m samples from bernoulli distribution with true mean = mu2\n",
        "    sample2=np.random.binomial(m,mu2)\n",
        "    mean2=np.mean(sample2)\n",
        "    \n",
        "    reward+=np.sum(sample2)  # Total reward from first arm while exploration\n",
        "\n",
        "\n",
        "# Exploiting the arm with the higher observed mean    \n",
        "    if mean1<mean2:\n",
        "        sample3=np.random.binomial(T-2*m,mu2) # Taking the remaining samples from arm 2\n",
        "        reward+=np.sum(sample3)\n",
        "    else:\n",
        "        sample4=np.random.binomial(T-2*m,mu1) # Taking the remaining samples from arm 1\n",
        "        reward+=np.sum(sample4)\n",
        "\n",
        "    regret= mu2*T - reward # Final regret\n",
        "\n",
        "    return regret\n",
        "\n",
        "regret_results_ETC=[]\n",
        "regret_results_UCB=[]\n",
        "\n",
        "for delta in delta_values:\n",
        "    regrets_ETC = [run_ETC_experiment(T, delta) for _ in range(num_experiments)]\n",
        "    average_regret_ETC = np.mean(regrets_ETC)\n",
        "    regret_results_ETC.append(average_regret_ETC)\n",
        "\n",
        "\n",
        "    regret_ucb = [ucb_algorithm(T, delta) for _ in range(num_experiments)]\n",
        "    average_regret_ucb = np.mean(regret_ucb)\n",
        "    regret_results_UCB.append(average_regret_ucb)\n",
        "\n",
        "\n",
        "# Plotting the graph\n",
        "plt.plot(delta_values, regret_results_ETC, marker='o', label='ETC')\n",
        "plt.plot(delta_values, regret_results_UCB, marker='x', label='UCB')\n",
        "plt.xlabel(' (Delta)')\n",
        "plt.ylabel('Estimated Regret')\n",
        "plt.title('Estimated Regret Comparison: Improved ETC vs. UCB')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
